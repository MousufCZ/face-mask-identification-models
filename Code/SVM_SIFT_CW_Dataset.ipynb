{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGplAdEddKBt6ftUVAnPvT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QcJK3kXl--c3"},"source":["# CV Coursework: Model 1: SIFT & SVM on original dataset\n","\n","- **Module:** Computer Vision - IN3060/INM460\n","- **Module leader:** [Giacomo Tarroni](mailto:giacomo.tarroni@city.ac.uk)\n","- **CW Owner:** Mousuf C Zaman - Student No: 180021356"]},{"cell_type":"markdown","metadata":{"id":"6rVDkKZEEKIp"},"source":["# Google Colab & Env Setup"]},{"cell_type":"code","metadata":{"id":"Kl3ZyAAVEKI1"},"source":["!pip install opencv-python==4.5.5.64\n","\n","import os\n","from google.colab import drive\n","import numpy as np\n","from skimage import io\n","from collections import Counter\n","import sys\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import cv2\n","from skimage import color, img_as_ubyte\n","from sklearn.cluster import MiniBatchKMeans\n","import random\n","from joblib import dump, load\n","from sklearn import metrics\n","\n","drive.mount('/content/drive')\n","\n","# TODO: Fill in the Google Drive path where you uploaded the lab materials\n","# Example: GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/Lab materials 01-20210104'\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '11 - University/Colab Notebooks/Computer Vision Lab/CW_Folder_UG' \n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data loading"],"metadata":{"id":"vm4DWDO0xXrr"}},{"cell_type":"code","source":["# Identify path to zipped dataset\n","zip_path = os.path.join(GOOGLE_DRIVE_PATH, 'CW_Dataset/CV2023_CW_Dataset.zip')\n","\n","# Copy it to Colab\n","!cp '{zip_path}' .\n","\n","# Unzip it\n","!yes|unzip -q CV2023_CW_Dataset.zip\n","\n","# Delete zipped version from Colab (not from Drive)\n","!rm CV2023_CW_Dataset.zip\n","\n","\n","def load_images_and_labels(train_path, test_path):\n","    images = []\n","    labels = []\n","\n","    # Load images and labels from train folder\n","    train_images_path = os.path.join(train_path, 'images')\n","    train_labels_path = os.path.join(train_path, 'labels')\n","    train_img_files = [f for f in os.listdir(train_images_path) if f.endswith('.jpeg')]\n","    for img_file in train_img_files:\n","        # Load the image and append to images list\n","        img_path = os.path.join(train_images_path, img_file)\n","        print('Loading image:', img_path)\n","        image = io.imread(img_path)\n","        images.append(image)\n","\n","        # Load the label if it exists and append to labels list\n","        label_path = os.path.join(train_labels_path, img_file[:-5] + '.txt')\n","        if os.path.exists(label_path):\n","            with open(label_path, 'r') as f:\n","                label = int(f.read().strip())\n","            labels.append(label)\n","            print('Label for image', img_path, ':', label)\n","        else:\n","            print('No label found for image:', img_path)\n","\n","    # Load images and labels from test folder\n","    test_images_path = os.path.join(test_path, 'images')\n","    test_labels_path = os.path.join(test_path, 'labels')\n","    test_img_files = [f for f in os.listdir(test_images_path) if f.endswith('.jpeg')]\n","    for img_file in test_img_files:\n","        # Load the image and append to images list\n","        img_path = os.path.join(test_images_path, img_file)\n","        #print('Loading image:', img_path)\n","        image = io.imread(img_path)\n","        images.append(image)\n","\n","        # Load the label if it exists and append to labels list\n","        label_path = os.path.join(test_labels_path, img_file[:-5] + '.txt')\n","        if os.path.exists(label_path):\n","            with open(label_path, 'r') as f:\n","                label = int(f.read().strip())\n","            labels.append(label)\n","            #print('Label for image', img_path, ':', label)\n","        else:\n","            print('No label found for image:', img_path)\n","\n","    # Count the number of images per label class\n","    label_counts = Counter(labels)\n","    print('Number of images per label class:', label_counts)\n","\n","    return images, labels, label_counts\n","\n","###############################################\n","train_path = 'train'\n","test_path = 'test'\n","images, labels, label_counts = load_images_and_labels(train_path, test_path)\n","\n","# Tes if image has loaded correctly\n","# Generate 1 random index for a train image\n","train_idx = np.random.choice(range(len(images)), size=1, replace=False)[0]\n","train_filtered_image = images[train_idx]\n","train_filtered_label = labels[train_idx]\n","\n","# Generate 1 random index for a test image\n","test_index = np.random.choice(range(len(images)-1), size=1, replace=False)[0]\n","test_filtered_image = images[test_index]\n","test_filtered_label = labels[test_index]\n","\n","# Plot the random train image\n","fig, axs = plt.subplots(1, 2, figsize=(4, 2))\n","axs[0].imshow(train_filtered_image)\n","axs[0].set_title('Train Image Label: ' + str(train_filtered_label))\n","\n","# Plot the random test image\n","axs[1].imshow(test_filtered_image)\n","axs[1].set_title('Test Image Label: ' + str(test_filtered_label))\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Y8yMnrXJxbNd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implementing feature descriptor"],"metadata":{"id":"khLgbOOj9aFa"}},{"cell_type":"code","source":["# Unbalanced problem\n","# Split the data into training and test sets, stratified by the labels\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42)\n","\n","# Initialize SIFT detector\n","sift = cv2.SIFT_create()\n","\n","# Create empty lists for feature descriptors and labels\n","des_list = []\n","y_train_list = []\n","\n","fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)\n","\n","# Define target size\n","target_size = (256, 256)\n","\n","# Loop over each image in the training set\n","for i in range(len(X_train)):\n","    # Load the image and resize to target size\n","    img = cv2.resize(X_train[i], target_size)\n","    \n","    # Convert to grayscale\n","    img_gray = img_as_ubyte(color.rgb2gray(img))\n","    \n","    # Detect keypoints and extract descriptors with SIFT\n","    kp, des = sift.detectAndCompute(img_gray, None)\n","\n","    # Show results for first 10 images\n","    if i < 10:\n","        row, col = i // 5, i % 5\n","        img_with_SIFT = cv2.drawKeypoints(img_gray, kp, img_gray)\n","        ax[row][col].imshow(img_with_SIFT)\n","        ax[row][col].set_axis_off()\n","\n","    # Append list of descriptors and label to respective lists\n","    if des is not None:\n","        des_list.append(des)\n","        y_train_list.append(y_train[i])\n","\n","# Convert to array for easier handling\n","des_array = np.vstack(des_list)\n","\n","#########################################################################\n","## Clustering the descriptors\n","# Number of centroids/codewords: good rule of thumb is 10*num_classes\n","k = len(np.unique(y_train)) * 10\n","\n","# Use MiniBatchKMeans for faster computation and lower memory usage\n","batch_size = des_array.shape[0] // 4\n","kmeans = MiniBatchKMeans(n_clusters=k, batch_size=batch_size).fit(des_array)\n","\n","\n","###################################################################\n","# Testing clustering\n","# Load a test image\n","test_img = X_train[0]\n","test_img_gray = img_as_ubyte(color.rgb2gray(test_img))\n","\n","# Detect keypoints and extract descriptors with SIFT\n","kp, des = sift.detectAndCompute(test_img_gray, None)\n","\n","# Predict visual words for the descriptors using the trained KMeans model\n","visual_words = kmeans.predict(des)\n","\n","print(visual_words)\n","\n","###################################################################\n","# Histogram\n","# Convert descriptors into histograms of codewords for each image\n","hist_list = []\n","idx_list = []\n","\n","for des in des_list:\n","    hist = np.zeros(k)\n","\n","    idx = kmeans.predict(des)\n","    idx_list.append(idx)\n","    for j in idx:\n","        hist[j] = hist[j] + (1 / len(des))\n","    hist_list.append(hist)\n","\n","hist_array = np.vstack(hist_list)\n","\n","fig, ax = plt.subplots(figsize=(8, 3))\n","ax.hist(np.array(idx_list, dtype=object), bins=k)\n","ax.set_title('Codewords occurrence in training set')\n","plt.show()"],"metadata":{"id":"N9_MnhrU9eDP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training a classifier"],"metadata":{"id":"g-TxaFwH_M-W"}},{"cell_type":"code","source":["from train_SVM import train_rbf_SVM\n","##############################################################################\n","# TODO: Implementing a different type of SVM                                 #\n","##############################################################################\n","classifier = train_rbf_SVM(hist_array, y_train_list)\n","##############################################################################\n","#                             END OF YOUR CODE                               #\n","##############################################################################\n","\n","dump(classifier, 'SVM_SIFT_CWDataset.joblib') \n","classifier = load(os.path.join(MODEL_PATH, 'SVM_SIFT_CWDataset.joblib'))"],"metadata":{"id":"jevWkiUn9r_L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Carry out feature detector on the test set data"],"metadata":{"id":"j7dXU6HqIM6v"}},{"cell_type":"code","source":["hist_list = []\n","\n","for i in range(len(X_test)):\n","    img = img_as_ubyte(color.rgb2gray(X_test[i]))\n","    kp, des = sift.detectAndCompute(img, None)\n","\n","    if des is not None:\n","        hist = np.zeros(k)\n","\n","        idx = kmeans.predict(des)\n","\n","        for j in idx:\n","            hist[j] = hist[j] + (1 / len(des))\n","\n","        # hist = scale.transform(hist.reshape(1, -1))\n","        hist_list.append(hist)\n","\n","    else:\n","        hist_list.append(None)\n","\n","# Remove potential cases of images with no descriptors\n","idx_not_empty = [i for i, x in enumerate(hist_list) if x is not None]\n","hist_list = [hist_list[i] for i in idx_not_empty]\n","y_test = [y_test[i] for i in idx_not_empty]\n","hist_array = np.vstack(hist_list)\n","\n","##########################################################################\n","# Predict the classes of each test image\n","y_pred = classifier.predict(hist_array).tolist()"],"metadata":{"id":"rnBOjVp1H-Ii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Result"],"metadata":{"id":"R_IRjN8MBqUL"}},{"cell_type":"code","source":["fig, axes = plt.subplots(2, 2, figsize=(4, 4), sharex=True, sharey=True)\n","ax = axes.ravel()\n","\n","random_indices = random.sample(range(len(X_test)), 4)\n","\n","for i in range(4):\n","    ax[i].imshow(X_test[random_indices[i]])\n","    ax[i].set_title(f'Label: {y_test[random_indices[i]]} \\n Prediction: {y_pred[random_indices[i]]}')\n","    ax[i].set_axis_off()\n","\n","fig.tight_layout()\n","plt.show()\n","\n","print(f\"\"\"Classification report for classifier {classifier}:\n","      {metrics.classification_report(y_test, y_pred, zero_division=0)}\\n\"\"\")\n","\n","metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n","plt.show()"],"metadata":{"id":"l3ixk1ZSBnBH"},"execution_count":null,"outputs":[]}]}